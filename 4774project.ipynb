{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4774 Final Project\n",
    "### Instructor: Professor Yangfeng Ji\n",
    "### Team member: David Da Lian, Wilson Zheng, Jianing Cai, Zhengguang Wang\n",
    "### Topic Chosen: Brain Tumor Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Preprocessing\n",
    "In this sesction, we first build a Python custom class ReadImages which implements methods to read and proprocess Data and do train_test_validation split. \\\n",
    "We use the Image.convert() and Image.resize() to preprocess the data into grey scale and (380,360). From there, we use the PCA to conduct dimensionality reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Set the path to the folders containing the images and labels\n",
    "\n",
    "class ReadImages():\n",
    "    def __init__(self,parent_folder_path):\n",
    "        self.parent_folder_path = parent_folder_path\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {\"glioma_tumor\": 0, \"meningioma_tumor\": 1, \"no_tumor\": 2, \"pituitary_tumor\": 3}\n",
    "        self.training_images=None\n",
    "        self.training_labels=None\n",
    "        self.testing_images=None\n",
    "        self.testing_labels=None\n",
    "        self.validation_images=None\n",
    "        self.validation_labels=None\n",
    "\n",
    "    # Loop through each subfolder and read in the images and labels\n",
    "    def Reading(self):\n",
    "        pca = PCA(n_components=128)\n",
    "        for subfolder in os.listdir(self.parent_folder_path):\n",
    "            if subfolder.startswith('.'):\n",
    "                continue  \n",
    "            if not os.path.isdir(os.path.join(self.parent_folder_path, subfolder)):\n",
    "                continue\n",
    "            subfolder_path = os.path.join(self.parent_folder_path, subfolder)\n",
    "            for folder in os.listdir(subfolder_path):\n",
    "                if folder.startswith('.'):\n",
    "                    continue  \n",
    "                if not os.path.isdir(os.path.join(subfolder_path, folder)):\n",
    "                    continue\n",
    "                folder_path = os.path.join(subfolder_path, folder)\n",
    "                for file in os.listdir(folder_path):\n",
    "                    if file.startswith('.'):\n",
    "                        continue  # skip hidden files and folders\n",
    "                    if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "                        img = Image.open(os.path.join(folder_path, file))\n",
    "                        img = img.convert(\"L\")\n",
    "                        img=img.resize((380,360))\n",
    "                        img_array = np.array(img)\n",
    "                        self.images.append(img_array)  # add the image array to the list\n",
    "                        label_str = folder\n",
    "                        label = self.label_map[label_str]\n",
    "                        self.labels.append(label)\n",
    "        self.images=np.array(self.images)\n",
    "        pca = PCA(n_components=128)\n",
    "        self.images = pca.fit_transform(self.images.reshape(-1, 360*380))\n",
    "        ##self.images = self.images.reshape(-1, 128)\n",
    "        \n",
    "\n",
    "\n",
    "    def Split(self):\n",
    "        self.training_images, X_test_val, self.training_labels, y_test_val = train_test_split(self.images, self.labels, test_size=0.2, random_state=42)\n",
    "        self.testing_images,self.validation_images,self.testing_labels,self.validation_labels=train_test_split(\n",
    "            X_test_val, y_test_val, test_size=0.1, random_state=42)\n",
    "        \n",
    "    def get_training(self):\n",
    "        return self.training_images,self.training_labels\n",
    "    \n",
    "    def get_testing(self):\n",
    "        return self.testing_images,self.testing_labels\n",
    "    \n",
    "    def get_validation(self):\n",
    "        return self.validation_images,self.validation_labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Splits\n",
    "In this section, we simply call the method in our ReadImages class to get the training set, validation set, and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Factory = ReadImages(\"/Users/zhengguang/Downloads/archive (9)\")\n",
    "Factory.Reading()\n",
    "Factory.Split()\n",
    "X_train, y_train = Factory.get_training()\n",
    "X_test, y_test = Factory.get_testing()\n",
    "X_val, y_val = Factory.get_validation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Build classifiers\n",
    "Our two classifiers chosen are Multiple Layer Perceptron and Support Vector Machine. \\\n",
    "We use the method in sklearn to train these two model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.8500851788756388\n",
      "MLPC:\n",
      "Training Accuracy: 0.9835312140942167\n",
      "Testing Accuracy: 0.7666098807495741\n"
     ]
    }
   ],
   "source": [
    "# Build First Classifier (SVM) --------------------------------------------------\n",
    "print('SVM:')\n",
    "clf_svm = SVC(kernel='poly', C=0.2, gamma=0.1)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the training data\n",
    "print(\"Training Accuracy: {}\".format(clf_svm.score(X_train, y_train)))\n",
    "\n",
    "# Evaluate the classifier on the testing data\n",
    "print(\"Testing Accuracy: {}\".format(clf_svm.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# Build Second Classifier (MLPC) --------------------------------------------------\n",
    "print('MLPC:')\n",
    "clf_mlpc = MLPClassifier(hidden_layer_sizes=(64,), activation='relu', solver='adam', random_state=42)\n",
    "clf_mlpc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the training data\n",
    "print(\"Training Accuracy: {}\".format(clf_mlpc.score(X_train, y_train)))\n",
    "\n",
    "# Evaluate the classifier on the testing data\n",
    "print(\"Testing Accuracy: {}\".format(clf_mlpc.score(X_test, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Hyper-parameter tuning\n",
    "Instead of using the Grid Search method in sklearn, we used a Python Dictionary and nested for loops to fine-tune the best combination of hyper-parameters for SVM and MLPC across our hypothesis space of hyper-parameters. However, we admit that the hypothesis space for our hyper-parameter is arbitrary. \n",
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=poly, gamma=0.1, degree=0.01\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=0.1, degree=0.01\n",
      "Validation accuracy: 0.3484848484848485\n",
      "Hyperparameters: C=sigmoid, gamma=0.1, degree=0.01\n",
      "Validation accuracy: 0.3484848484848485\n",
      "Hyperparameters: C=poly, gamma=0.1, degree=0.1\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=0.1, degree=0.1\n",
      "Validation accuracy: 0.3484848484848485\n",
      "Hyperparameters: C=sigmoid, gamma=0.1, degree=0.1\n",
      "Validation accuracy: 0.3333333333333333\n",
      "Hyperparameters: C=poly, gamma=0.1, degree=1\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=0.1, degree=1\n",
      "Validation accuracy: 0.3484848484848485\n",
      "Hyperparameters: C=sigmoid, gamma=0.1, degree=1\n",
      "Validation accuracy: 0.3333333333333333\n",
      "Hyperparameters: C=poly, gamma=1, degree=0.01\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=1, degree=0.01\n",
      "Validation accuracy: 0.5606060606060606\n",
      "Hyperparameters: C=sigmoid, gamma=1, degree=0.01\n",
      "Validation accuracy: 0.3181818181818182\n",
      "Hyperparameters: C=poly, gamma=1, degree=0.1\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=1, degree=0.1\n",
      "Validation accuracy: 0.5606060606060606\n",
      "Hyperparameters: C=sigmoid, gamma=1, degree=0.1\n",
      "Validation accuracy: 0.3181818181818182\n",
      "Hyperparameters: C=poly, gamma=1, degree=1\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=1, degree=1\n",
      "Validation accuracy: 0.5606060606060606\n",
      "Hyperparameters: C=sigmoid, gamma=1, degree=1\n",
      "Validation accuracy: 0.3181818181818182\n",
      "Hyperparameters: C=poly, gamma=10, degree=0.01\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=10, degree=0.01\n",
      "Validation accuracy: 0.5606060606060606\n",
      "Hyperparameters: C=sigmoid, gamma=10, degree=0.01\n",
      "Validation accuracy: 0.3181818181818182\n",
      "Hyperparameters: C=poly, gamma=10, degree=0.1\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=10, degree=0.1\n",
      "Validation accuracy: 0.5606060606060606\n",
      "Hyperparameters: C=sigmoid, gamma=10, degree=0.1\n",
      "Validation accuracy: 0.3181818181818182\n",
      "Hyperparameters: C=poly, gamma=10, degree=1\n",
      "Validation accuracy: 0.9393939393939394\n",
      "Hyperparameters: C=rbf, gamma=10, degree=1\n",
      "Validation accuracy: 0.5606060606060606\n",
      "Hyperparameters: C=sigmoid, gamma=10, degree=1\n",
      "Validation accuracy: 0.3181818181818182\n",
      "Best hyperparameters:  {'kernel': 'poly', 'C': 0.1, 'gamma': 0.01}\n",
      "Validation accuracy:  0.9393939393939394\n",
      "Test accuracy:  0.8500851788756388\n"
     ]
    }
   ],
   "source": [
    "#Define the hyperparameters to search over\n",
    "c_values = [0.1, 1, 10]\n",
    "gamma_values = [0.01, 0.1, 1]\n",
    "kernel_values = ['poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Create empty lists to store the results\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for c in c_values:\n",
    "    for gamma in gamma_values:\n",
    "        for kernel in kernel_values:\n",
    "            # Create the SVM classifier with the current hyperparameters\n",
    "            clf_svm = SVC(kernel=kernel, C=c, gamma=gamma)\n",
    "\n",
    "            # Train the classifier on the training set\n",
    "            clf_svm.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the classifier on the validation set\n",
    "            y_pred = clf_svm.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "            # Print out the current hyperparameters and their validation accuracy\n",
    "            print(\"Hyperparameters: C={}, gamma={}, degree={}\".format(kernel, c, gamma))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy))\n",
    "\n",
    "            # Update the best hyperparameters if the current model is better\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'kernel': kernel, 'C': c, 'gamma': gamma}\n",
    "\n",
    "# Print out the best hyperparameters and their validation accuracy\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "print(\"Validation accuracy: \", best_accuracy)\n",
    "\n",
    "# Create the SVM classifier with the best hyperparameters\n",
    "clf_svm = SVC(kernel=best_params['kernel'], C=best_params['C'], gamma=best_params['gamma'])\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print out the test accuracy\n",
    "print(\"Test accuracy: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(100,), rate=constant\n",
      "Validation accuracy: 0.8636363636363636\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(100,), rate=invscaling\n",
      "Validation accuracy: 0.803030303030303\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(100,), rate=adaptive\n",
      "Validation accuracy: 0.8787878787878788\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(150,), rate=constant\n",
      "Validation accuracy: 0.8636363636363636\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(150,), rate=invscaling\n",
      "Validation accuracy: 0.8939393939393939\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(150,), rate=adaptive\n",
      "Validation accuracy: 0.8484848484848485\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(200,), rate=constant\n",
      "Validation accuracy: 0.9242424242424242\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(200,), rate=invscaling\n",
      "Validation accuracy: 0.8636363636363636\n",
      "Hyperparameters: indiv_activation=logistic, indiv_layer_size=(200,), rate=adaptive\n",
      "Validation accuracy: 0.8939393939393939\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(100,), rate=constant\n",
      "Validation accuracy: 0.7727272727272727\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(100,), rate=invscaling\n",
      "Validation accuracy: 0.7424242424242424\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(100,), rate=adaptive\n",
      "Validation accuracy: 0.7424242424242424\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(150,), rate=constant\n",
      "Validation accuracy: 0.696969696969697\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(150,), rate=invscaling\n",
      "Validation accuracy: 0.7121212121212122\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(150,), rate=adaptive\n",
      "Validation accuracy: 0.803030303030303\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(200,), rate=constant\n",
      "Validation accuracy: 0.8181818181818182\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(200,), rate=invscaling\n",
      "Validation accuracy: 0.8181818181818182\n",
      "Hyperparameters: indiv_activation=tanh, indiv_layer_size=(200,), rate=adaptive\n",
      "Validation accuracy: 0.7878787878787878\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(100,), rate=constant\n",
      "Validation accuracy: 0.9242424242424242\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(100,), rate=invscaling\n",
      "Validation accuracy: 0.8636363636363636\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(100,), rate=adaptive\n",
      "Validation accuracy: 0.8484848484848485\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(150,), rate=constant\n",
      "Validation accuracy: 0.8333333333333334\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(150,), rate=invscaling\n",
      "Validation accuracy: 0.8787878787878788\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(150,), rate=adaptive\n",
      "Validation accuracy: 0.8787878787878788\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(200,), rate=constant\n",
      "Validation accuracy: 0.9696969696969697\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(200,), rate=invscaling\n",
      "Validation accuracy: 0.9545454545454546\n",
      "Hyperparameters: indiv_activation=relu, indiv_layer_size=(200,), rate=adaptive\n",
      "Validation accuracy: 0.8787878787878788\n",
      "Best hyperparameters:  {'Activation': 'relu', 'layer_size': (200,), 'learning rate': 'constant'}\n",
      "Validation accuracy:  0.9696969696969697\n",
      "Test accuracy:  0.7853492333901193\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "activation = [\"logistic\",\"tanh\",\"relu\"]\n",
    "hidden_layer_size=[(100,),(150,),(200,)]\n",
    "learning_rate = [\"constant\",\"invscaling\",\"adaptive\"]\n",
    "\n",
    "# Create empty lists to store the results\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for indiv_activation in activation:\n",
    "    for indiv_layer_size in hidden_layer_size:\n",
    "        for rate in learning_rate:\n",
    "            # Create the SVM classifier with the current hyperparameters\n",
    "            clf_mlpc = MLPClassifier(activation=indiv_activation,hidden_layer_sizes=indiv_layer_size,learning_rate=rate,max_iter=200)\n",
    "\n",
    "            # Train the classifier on the training set\n",
    "            clf_mlpc.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the classifier on the validation set\n",
    "            y_pred = clf_mlpc.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "            # Print out the current hyperparameters and their validation accuracy\n",
    "            print(\"Hyperparameters: indiv_activation={}, indiv_layer_size={}, rate={}\".format(indiv_activation, indiv_layer_size, rate))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy))\n",
    "\n",
    "            # Update the best hyperparameters if the current model is better\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\"Activation\":indiv_activation,'layer_size': indiv_layer_size, \"learning rate\":rate}\n",
    "\n",
    "# Print out the best hyperparameters and their validation accuracy\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "print(\"Validation accuracy: \", best_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "clf_mlpc_best = MLPClassifier(activation=best_params[\"Activation\"],hidden_layer_sizes=best_params[\"layer_size\"],\n",
    "                              learning_rate=best_params[\"learning rate\"])\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf_mlpc_best.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf_mlpc_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print out the test accuracy\n",
    "print(\"Test accuracy: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Analysis\n",
    "- Based on the results above, which classifier is better, and why?\n",
    "\n",
    "- We can evaluate which classifier is better by looking at the test accuracies obtained in the above sections after hyperparameter tuning. The accuracy for SVM is around 0.85, while the accuracy for MLPC is around 0.785, hence we can conclude that SVM is better.\n",
    "\n",
    "- For further improvement on classification accuracy, what strategies that you can use and why do you think they will be helpful?\n",
    "\n",
    "1. Feature engineering: By selecting and processing certain features from the raw input data, we can improve the quality of the input data for the classifier. Since only the most relavent features are being used, the classifier can better distinguish between the different classes, thus producing a more accurate model. In our case, this might be ensuring that the model doesn't pay too much attention to the black spaces around the head, the neck portion, and lower half of the head.\n",
    "\n",
    "2. Data Augmentation: Generate additional training from the existing ones by appyling transformations. This technique would allow us to have more training data that can be used to better train the classifier, since it will have more exposure to different data. Since we are dealing with images that have very sensitive information, we need to make sure that the transformations we apply keep the crucial information constant, so the labels aren't messed up.\n",
    "\n",
    "3. Regularization. Apart from the L2 regularization that we focused during hyperparameter tuning (constant c in SVM), there are many other regularization techniques that we can implement when training the models. For SVM, examples include L1 regularization to encourage a simpler decision boundary, and norm constraints which can be used to limit the size of the weight vector. For MLPC, we didn't incorporate any regularization. Some examples of techniques we can use are L1 and L2 regularization just as explained above, as well as dropout which randomly drops out some neurons during training to prevent overfitting, and weight decay whic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
